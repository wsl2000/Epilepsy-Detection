# -*- coding: utf-8 -*-
"""
æ¨ç†è„šæœ¬ï¼šè½½å…¥CBraMod-inspired Stitched Transformeræ¨¡å‹
å¤ç”¨train_tf_stitch.pyä¸­çš„æ¨¡å‹å®šä¹‰ï¼Œä¸ä¸»åŠæ–¹æ¥å£ä¿æŒä¸€è‡´ã€‚
"""

from typing import List, Dict, Any
import json, torch, numpy as np
from scipy import signal
import os
from torch import nn

# å¯¼å…¥è®­ç»ƒè„šæœ¬ä¸­çš„æ¨¡å‹å’Œç»„ä»¶
from train_tf_stitch import (
    OptimizedStitchedTransformer,
    StitchedEEGTransformer,
    MultiHeadChannelAttention,
    EfficientPatchEmbedding,
    EfficientCrissCrossLayer,
    add_frequency_features,
    DEVICE, TARGET_FS, WIN_SEC, STEP_SEC, WIN_SAMP, STEP_SAMP
)
from wettbewerb import get_6montages

def load_model_from_metadata(model_name: str):
    """
    ä»å…ƒæ•°æ®æ–‡ä»¶åŠ è½½æ¨¡å‹é…ç½®å’Œæƒé‡
    
    Args:
        model_name: æ¨¡å‹å…ƒæ•°æ®JSONæ–‡ä»¶è·¯å¾„
        
    Returns:
        model: åŠ è½½å®Œæˆçš„æ¨¡å‹
        params: æ¨¡å‹å‚æ•°å­—å…¸
    """
    # è¯»å–å…ƒæ•°æ®
    with open(model_name, "r") as f:
        params = json.load(f)
    
    # è·å–æ¨¡å‹ç±»å‹
    model_type = params.get("model_type", "OptimizedStitchedTransformer")
    
    # ä»å…ƒæ•°æ®ä¸­è·å–æ¨¡å‹å‚æ•°
    model_scale = params.get("model_scale", "small")
    input_channels = params.get("input_channels", 36)
    patch_size = params.get("patch_size", 16)
    dropout = params.get("dropout", 0.1)
    
    # æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºç›¸åº”çš„æ¨¡å‹
    if model_type == "OptimizedStitchedTransformer":
        # ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬çš„æ¨¡å‹ï¼ˆé€Ÿåº¦å¿«ï¼‰
        model = OptimizedStitchedTransformer(
            input_channels=input_channels,
            patch_size=patch_size,
            dropout=dropout,
            model_scale=model_scale
        ).to(DEVICE).eval()
    elif model_type == "StitchedEEGTransformer":
        # ä½¿ç”¨å®Œæ•´ç‰ˆæœ¬çš„æ¨¡å‹ï¼ˆåŠŸèƒ½å…¨ï¼‰
        d_model = params.get("d_model", 512)
        num_heads = params.get("num_heads", 8)
        num_layers = params.get("num_layers", 12)
        
        model = StitchedEEGTransformer(
            input_channels=input_channels,
            patch_size=patch_size,
            d_model=d_model,
            num_heads=num_heads,
            num_layers=num_layers,
            dropout=dropout,
            model_scale=model_scale
        ).to(DEVICE).eval()
    else:
        raise ValueError(f"Unknown model type: {model_type}")
    
    # åŠ è½½æ¨¡å‹æƒé‡
    model_weight_path = params["model_weight_path"]
    if not os.path.exists(model_weight_path):
        # å¦‚æœç»å¯¹è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•ç›¸å¯¹è·¯å¾„
        model_weight_path = os.path.join(os.path.dirname(model_name), 
                                       os.path.basename(model_weight_path))
    
    if not os.path.exists(model_weight_path):
        raise FileNotFoundError(f"Model weights not found: {model_weight_path}")
    
    # åŠ è½½æƒé‡
    state_dict = torch.load(model_weight_path, map_location=DEVICE)
    if "model_state_dict" in state_dict:
        model_state_dict = state_dict["model_state_dict"]
    else:
        model_state_dict = state_dict
    
    # å¤„ç†åŠ¨æ€åˆ›å»ºçš„pos_embeddingå‚æ•°
    # å¦‚æœçŠ¶æ€å­—å…¸ä¸­åŒ…å«pos_embeddingï¼Œéœ€è¦å…ˆåˆ›å»ºå®ƒ
    if "patch_embedding.pos_embedding" in model_state_dict:
        pos_embedding_tensor = model_state_dict["patch_embedding.pos_embedding"]
        
        # æ£€æŸ¥pos_embeddingçš„é€šé“æ•°æ˜¯å¦ä¸å½“å‰æ¨¡å‹åŒ¹é…
        saved_channels = pos_embedding_tensor.shape[1]  # (1, channels, patch_num, d_model)
        current_channels = input_channels
        
        if saved_channels != current_channels:
            print(f"âš ï¸ Channel mismatch: saved model has {saved_channels} channels, current model expects {current_channels}")
            print(f"   This likely means the model was trained with frequency features enabled.")
            print(f"   Enabling frequency features for inference to match training setup.")
            
            # è®¾ç½®é¢‘ç‡ç‰¹å¾æ ‡å¿—ï¼Œç¡®ä¿é¢„å¤„ç†æ—¶ä½¿ç”¨é¢‘ç‡ç‰¹å¾
            params["freq_bands"] = True
            
            # å¦‚æœè¿˜æ˜¯ä¸åŒ¹é…ï¼Œéœ€è¦è°ƒæ•´pos_embedding
            if saved_channels != current_channels:
                if saved_channels > current_channels:
                    # æˆªå–å‰é¢çš„é€šé“
                    pos_embedding_tensor = pos_embedding_tensor[:, :current_channels, :, :]
                    print(f"   Truncated pos_embedding from {saved_channels} to {current_channels} channels")
                else:
                    # é‡å¤æˆ–æ’å€¼æ¥æ‰©å±•é€šé“
                    repeat_factor = current_channels // saved_channels
                    remainder = current_channels % saved_channels
                    
                    repeated = pos_embedding_tensor.repeat(1, repeat_factor, 1, 1)
                    if remainder > 0:
                        extra = pos_embedding_tensor[:, :remainder, :, :]
                        pos_embedding_tensor = torch.cat([repeated, extra], dim=1)
                    else:
                        pos_embedding_tensor = repeated
                    print(f"   Expanded pos_embedding from {saved_channels} to {current_channels} channels")
        
        # æ‰‹åŠ¨æ³¨å†Œpos_embeddingå‚æ•°åˆ°æ¨¡å‹ä¸­
        model.patch_embedding.pos_embedding = nn.Parameter(pos_embedding_tensor)
    
    # ç°åœ¨å¯ä»¥å®‰å…¨åœ°åŠ è½½çŠ¶æ€å­—å…¸
    try:
        model.load_state_dict(model_state_dict, strict=True)
    except RuntimeError as e:
        print(f"âš ï¸ Strict loading failed: {e}")
        print("Trying non-strict loading...")
        # å¦‚æœä¸¥æ ¼åŠ è½½å¤±è´¥ï¼Œå°è¯•éä¸¥æ ¼åŠ è½½
        missing_keys, unexpected_keys = model.load_state_dict(model_state_dict, strict=False)
        if missing_keys:
            print(f"Missing keys: {missing_keys}")
        if unexpected_keys:
            print(f"Unexpected keys: {unexpected_keys}")
            # è¿‡æ»¤æ‰å·²çŸ¥çš„åŠ¨æ€å‚æ•°
            filtered_unexpected = [k for k in unexpected_keys if "pos_embedding" not in k]
            if filtered_unexpected:
                print(f"âš ï¸ Still have unexpected keys after filtering: {filtered_unexpected}")
    
    print(f"âœ… Loaded {model_type} with {sum(p.numel() for p in model.parameters()):,} parameters")
    
    return model, params

def preprocess_eeg_data(channels: List[str], data: np.ndarray, fs: float, 
                       target_fs: int = TARGET_FS, use_freq_bands: bool = False) -> np.ndarray:
    """
    EEGæ•°æ®é¢„å¤„ç†æµç¨‹
    
    Args:
        channels: é€šé“ååˆ—è¡¨
        data: EEGæ•°æ® (channels, samples)
        fs: é‡‡æ ·ç‡
        target_fs: ç›®æ ‡é‡‡æ ·ç‡
        use_freq_bands: æ˜¯å¦ä½¿ç”¨é¢‘ç‡ç‰¹å¾å¢å¼º
        
    Returns:
        mdata: é¢„å¤„ç†åçš„æ•°æ® (montages, samples)
    """
    # ä½¿ç”¨6å¯¼è”è’™å¤ªå¥‡
    _, mdata, _ = get_6montages(channels, data)
    
    # é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡
    if fs != target_fs:
        mdata = signal.resample_poly(mdata, target_fs, int(fs), axis=1)
    
    # å¢å¼ºå½’ä¸€åŒ–ï¼šrobust z-score
    median = np.median(mdata, axis=1, keepdims=True)
    mad = np.median(np.abs(mdata - median), axis=1, keepdims=True)
    mdata = (mdata - median) / (mad + 1e-7)
    
    # å¦‚æœå¯ç”¨é¢‘ç‡ç‰¹å¾ï¼Œéœ€è¦æ‰©å±•åˆ°36é€šé“ä»¥åŒ¹é…è®­ç»ƒæ—¶çš„æ¨¡å‹
    if use_freq_bands:
        mdata = add_frequency_features(mdata) 
    
    return mdata

def create_sliding_windows(mdata: np.ndarray, win_samp: int, step_samp: int, 
                         use_freq_bands: bool = False) -> np.ndarray:
    """
    åˆ›å»ºæ»‘åŠ¨çª—å£
    
    Args:
        mdata: é¢„å¤„ç†åçš„EEGæ•°æ®
        win_samp: çª—å£å¤§å°ï¼ˆæ ·æœ¬æ•°ï¼‰
        step_samp: æ­¥é•¿ï¼ˆæ ·æœ¬æ•°ï¼‰
        use_freq_bands: æ˜¯å¦æ·»åŠ é¢‘ç‡ç‰¹å¾
        
    Returns:
        segments: åˆ†æ®µæ•°æ® (n_segments, channels, win_samp)
    """
    n_seg = max(0, (mdata.shape[1] - win_samp) // step_samp + 1)
    
    if n_seg == 0:
        return np.array([])
    
    segments = []
    for s in range(0, n_seg * step_samp, step_samp):
        window = mdata[:, s:s + win_samp]
        
        # æ·»åŠ é¢‘ç‡åŸŸç‰¹å¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_freq_bands:
            window = add_frequency_features(window)
        
        segments.append(window)
    
    return np.stack(segments)

def model_inference(model, segments: np.ndarray, batch_size: int = 16) -> np.ndarray:
    """
    æ¨¡å‹æ¨ç†
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        segments: åˆ†æ®µæ•°æ®
        batch_size: æ‰¹å¤„ç†å¤§å°
        
    Returns:
        probs: ç™«ç—«æ¦‚ç‡æ•°ç»„
    """
    all_probs = []
    
    with torch.no_grad():
        for i in range(0, len(segments), batch_size):
            batch = segments[i:i + batch_size]
            batch_tensor = torch.tensor(batch, dtype=torch.float32).to(DEVICE)
            
            try:
                logits = model(batch_tensor)
                probs = torch.softmax(logits, 1)[:, 1].cpu().numpy()
                all_probs.extend(probs)
            except Exception as e:
                print(f"âš ï¸ Inference error for batch {i//batch_size}: {e}")
                # å¦‚æœæ¨ç†å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä½æ¦‚ç‡
                probs = np.zeros(len(batch))
                all_probs.extend(probs)
    
    return np.array(all_probs)

def postprocess_predictions(probs: np.ndarray, prob_th: float, min_len: int, 
                          step_sec: float, win_sec: float) -> Dict[str, Any]:
    """
    åå¤„ç†é¢„æµ‹ç»“æœ
    
    Args:
        probs: ç™«ç—«æ¦‚ç‡æ•°ç»„
        prob_th: æ¦‚ç‡é˜ˆå€¼
        min_len: æœ€å°è¿ç»­é•¿åº¦
        step_sec: æ­¥é•¿ï¼ˆç§’ï¼‰
        win_sec: çª—å£é•¿åº¦ï¼ˆç§’ï¼‰
        
    Returns:
        result: é¢„æµ‹ç»“æœå­—å…¸
    """
    # å¹³æ»‘å¤„ç†
    smooth_window = min(5, len(probs))
    if smooth_window > 1:
        smooth = np.convolve(probs, np.ones(smooth_window) / smooth_window, mode="same")
    else:
        smooth = probs
    
    # åº”ç”¨é˜ˆå€¼
    mask = smooth > prob_th
    
    # å¯»æ‰¾è¿é€šåŸŸ
    runs, current = [], []
    for i, m in enumerate(mask):
        if m:
            current.append(i)
        elif current:
            if len(current) >= min_len:
                runs.append(current)
            current = []
    if current and len(current) >= min_len:
        runs.append(current)
    
    if not runs:  # æ— ç™«ç—«æ£€æµ‹
        return {
            "seizure_present": False,
            "seizure_confidence": float(smooth.max()) if len(smooth) > 0 else 0.0,
            "onset": -1,
            "onset_confidence": 0.0,
            "offset": -1,
            "offset_confidence": 0.0
        }
    
    # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„è¿é€šåŸŸ
    best_run = max(runs, key=lambda r: smooth[r].max())
    onset_sec = best_run[0] * step_sec
    offset_sec = best_run[-1] * step_sec + win_sec
    
    # è®¡ç®—ç½®ä¿¡åº¦
    conf = float(smooth[best_run].mean())
    max_conf = float(smooth[best_run].max())
    
    return {
        "seizure_present": True,
        "seizure_confidence": max_conf,
        "onset": onset_sec,
        "onset_confidence": conf,
        "offset": offset_sec,
        "offset_confidence": conf
    }

def predict_labels(channels: List[str], data: np.ndarray,
                   fs: float, reference_system: str,
                   model_name: str = "model_tf_optimized.json") -> Dict[str, Any]:
    """
    ä¸»é¢„æµ‹å‡½æ•°ï¼Œä¸ä¸»åŠæ–¹æ¥å£ä¿æŒä¸€è‡´
    
    Args:
        channels: EEGé€šé“ååˆ—è¡¨
        data: EEGæ•°æ®çŸ©é˜µ (channels, samples)
        fs: é‡‡æ ·ç‡
        reference_system: å‚è€ƒç³»ç»Ÿï¼ˆ"LE", "AR", "Sz"ç­‰ï¼‰
        model_name: æ¨¡å‹å…ƒæ•°æ®æ–‡ä»¶å
        
    Returns:
        result: é¢„æµ‹ç»“æœå­—å…¸ï¼ŒåŒ…å«ç™«ç—«æ£€æµ‹å’Œå®šä½ä¿¡æ¯
    """
    try:
        # 1. åŠ è½½æ¨¡å‹ï¼ˆè¿™é‡Œä¼šè‡ªåŠ¨æ£€æµ‹å’Œè®¾ç½®é¢‘ç‡ç‰¹å¾æ ‡å¿—ï¼‰
        model, params = load_model_from_metadata(model_name)
        
        # 2. è·å–æ¨ç†å‚æ•°
        prob_th = params.get("prob_th", 0.5)
        min_len = params.get("min_len", 2)
        win_sec = params.get("win_sec", WIN_SEC)
        step_sec = params.get("step_sec", STEP_SEC)
        target_fs = params.get("fs", TARGET_FS)
        use_freq_bands = params.get("freq_bands", False)  # ä»æ¨¡å‹åŠ è½½æ—¶å¯èƒ½ä¼šè¢«è‡ªåŠ¨è®¾ç½®
        
        print(f"ğŸ”§ Inference settings: freq_bands={use_freq_bands}, channels={params.get('input_channels', 36)}")
        
        # 3. æ•°æ®é¢„å¤„ç†ï¼ˆæ ¹æ®æ¨¡å‹éœ€æ±‚å†³å®šæ˜¯å¦ä½¿ç”¨é¢‘ç‡ç‰¹å¾ï¼‰
        mdata = preprocess_eeg_data(channels, data, fs, target_fs, use_freq_bands)
        
        print(f"ğŸ“Š Preprocessed data shape: {mdata.shape} (expected channels: {params.get('input_channels', 36)})")
        
        # éªŒè¯é€šé“æ•°æ˜¯å¦åŒ¹é…
        expected_channels = params.get("input_channels", 36)
        if mdata.shape[0] != expected_channels:
            print(f"âš ï¸ Channel count mismatch: got {mdata.shape[0]}, expected {expected_channels}")
            if mdata.shape[0] == 6 and expected_channels == 36:
                print("   Model was trained with frequency features, but inference data only has 6 montage channels")
                # å¼ºåˆ¶å¯ç”¨é¢‘ç‡ç‰¹å¾ - ä¿®æ­£å‡½æ•°è°ƒç”¨
                mdata = add_frequency_features(mdata)  # åªä¼ é€’ä¸€ä¸ªå‚æ•°
                print(f"   Applied frequency features, new shape: {mdata.shape}")
        
        # 4. åˆ›å»ºæ»‘åŠ¨çª—å£
        win_samp = int(win_sec * target_fs)
        step_samp = int(step_sec * target_fs)
        segments = create_sliding_windows(mdata, win_samp, step_samp, use_freq_bands=False)  # é¢‘ç‡ç‰¹å¾å·²åœ¨é¢„å¤„ç†ä¸­æ·»åŠ 
        
        if len(segments) == 0:  # å½•éŸ³å¤ªçŸ­
            return {
                "seizure_present": False,
                "seizure_confidence": 0.0,
                "onset": -1,
                "onset_confidence": 0.0,
                "offset": -1,
                "offset_confidence": 0.0
            }
        
        print(f"ğŸ“ Created {len(segments)} segments, shape: {segments[0].shape}")
        
        # 5. æ¨¡å‹æ¨ç†
        probs = model_inference(model, segments, batch_size=16)
        
        # 6. åå¤„ç†
        result = postprocess_predictions(probs, prob_th, min_len, step_sec, win_sec)
        
        return result
        
    except Exception as e:
        print(f"âŒ Prediction error: {e}")
        import traceback
        traceback.print_exc()
        # è¿”å›å®‰å…¨çš„é»˜è®¤ç»“æœ
        return {
            "seizure_present": False,
            "seizure_confidence": 0.0,
            "onset": -1,
            "onset_confidence": 0.0,
            "offset": -1,
            "offset_confidence": 0.0
        }

# æµ‹è¯•å‡½æ•°
def test_prediction():
    """æµ‹è¯•é¢„æµ‹å‡½æ•°"""
    # æ¨¡æ‹Ÿæ•°æ®
    channels = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',
                'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']
    fs = 500.0
    duration = 60  # 60ç§’
    n_samples = int(fs * duration)
    
    # ç”ŸæˆéšæœºEEGæ•°æ®
    np.random.seed(42)
    data = np.random.randn(len(channels), n_samples) * 50  # å¾®ä¼çº§åˆ«
    
    # æ·»åŠ ä¸€äº›æ¨¡æ‹Ÿçš„ç™«ç—«æ ·æ´»åŠ¨
    seizure_start = int(20 * fs)
    seizure_end = int(30 * fs)
    data[:, seizure_start:seizure_end] += np.random.randn(len(channels), seizure_end - seizure_start) * 100
    
    # è¿›è¡Œé¢„æµ‹
    result = predict_labels(channels, data, fs, "LE", "model_tf_optimized.json")
    
    print("ğŸ§ª æµ‹è¯•é¢„æµ‹ç»“æœ:")
    for key, value in result.items():
        print(f"   {key}: {value}")

if __name__ == "__main__":
    test_prediction()
